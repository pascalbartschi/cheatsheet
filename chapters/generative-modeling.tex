\section*{Generative Modeling}

Estimate $p(x,y) \propto p(x|y) \cdot p(y)$  (Bayes)

\subsection*{Gaussian Bayes Classifier}

No iid,  we model features with a multivariate Gaussian $\mathcal{N}(x; \mu_y, \Sigma_y)$:

\quad $\mu_{y} = \frac{1}{\text{Count}(Y = y)} \sum_{j \; | \; y_j = y} x_{j}$

\quad $\Sigma_{y} = \frac{1}{\text{Count}(Y = y)} \sum_{j \; | \; y_j = y} (x_{j} - \hat \mu_{y}) (x_{j} - \hat \mu_{y})^\top$

= \textbf{quadratic discriminant analysis} (QDA). LDA: $\Sigma_+ = \Sigma_-$, Fisher LDA: $p(y) = \frac{1}{2}$, classify $x$ as outlier if: $p(x) \leq \tau$.

\subsection*{Gaussian Naive Bayes Classifier}
Assumes: $p(x_1, \ldots, x_d \mid y) = \prod_{j=1}^{d} p(x_j \mid y)$

$\rightarrow$GBC with diagonal $\Sigma$s. 

\textbf{Parameter estimation via MLE}

Features: $p(x_i \; | \; y) = \mathcal{N}(x_i; \hat \mu_{y,i}, \sigma^2_{y,i})$ \\[-6pt]

\quad \quad$p(\hat{y}) = \frac{n_y}{n} \text{ (class prior)}$

\quad \quad$\hat{\mu}_{y,j} = \frac{1}{n_y} \sum_{i: y_i = y} x_{i,j}$

\quad \quad$\hat{\sigma}^2_{y,j} = \frac{1}{n_y} \sum_{i: y_i = y} \left( x_{i,j} - \hat{\mu}_{y,j} \right)^2$

\textbf{Predict by:} \\[-20pt]
$$y = \argmax{\hat y} \; p(\hat y \; | \; x) = \argmax{\hat y} \; p(\hat y) \cdot \prod_{i=1}^d p(x_i \; | \; \hat y) $$


$= \arg \max_{y} \left( \log \hat{p}(y) + \sum_{j=1}^{d} \log \hat{p}(x_j \mid y) \right)
$

= decision rule for bin. class.: \\[-8pt]

\qquad \qquad $y = \sgn \left( \color{Red} \log \frac{p(Y = +1 \; | \; x)}{p(Y = -1 \; | \; x)} \color{Black} \right)$ \\[-3pt]

With discriminant \color{Red}$f(x)$\color{Black} for violated cond. iid assumption classifier can be overconfident.

\textbf{Avoiding Overfitting}

MLE is prone to overfitting. Avoid this by restricting model class (fewer parameters, e.g. GNB) or using priors (restrict param. values).

\subsection*{Generative vs. Discriminative}

\textbf{Discriminative models}:

$p(y | x)$, can't detect outliers, more robust

\textbf{Generative models}:

$p(x,y)$, can be more powerful (detect outliers, missing values) if assumptions are met, are typically less robust against outliers

\section*{Classification}

\textbf{Zero-One loss} \quad not convex nor continuous

\qquad \qquad $\ell_{0-1}(\hat{f}(x), y) = \mathbb{I}_{y \neq \sgn \hat{f}(x)}$

\textbf{Logistic loss} \quad $\log(1 + e^{-y \hat{f}(x)})$

\textbf{Hinge loss} \quad \ $\max(0, 1-y \hat{f}(x))$

\textbf{Softmax} $p(1 | x) = \frac{1}{1 + e^{- \hat{f}(x)}}, p(-1 | x) = \frac{1}{1 + e^{\hat{f}(x)}}$ 

Cross-Entropy \ \ \ $\hat{p}_k = e^{\hat{f}_k(x)} / \sum_{i=1}^K e^{\hat{f}_j(x)}$

\subsection*{Linear Classifiers}

Dec. bound: $f(x) = w^\top x + b  = 0$

If data is lin. sep. GD  converges to \textbf{Maximum-Margin Solution}: 

$w_{\text{MM}} = \text{argmax} \; \underbrace{\text{min}_i y_i w^\top x_i (w)}_{\text{margin}(w)} \; \text{, } ||w||_2 = 1$ \\[-15pt]
 
\subsection*{SVMs}
 
\textbf{\textcolor{purple}{Soft SVM} / Hard SVM} \quad \textcolor{purple}{"slack"} 
$$\hat{w} = \min_{w, \xi} \frac{1}{2} ||w||_2^2 \textcolor{purple}{ + \lambda \sum_{i=1}^n \underbrace{\max (0, 1 - y_i w^\top x_i)}_{\text{hinge loss}}}$$ \\[-10pt]
$\text{s.t. } \forall i \;y_i w^\top x_i \geq 1 \textcolor{purple}{- \xi}$ 

\subsection*{Metrics} 
$\textbf{error}_1 / \textbf{FPR}: \frac{\text{FP}}{\text{TN + FP}}$
$\textbf{error}_2 / \text{FNR}: \frac{\text{FN}}{\text{TP + FN}}$
$\textbf{TPR / Recall}: \frac{\text{TP}}{\text{TP + FN}}$
$\textbf{TNR}: \frac{\text{TN}}{\text{TN + FP}}$
$\text{Precision}: \frac{\text{TP}}{\text{TP + FP}} = 1 - \text{FDR}$, FDR = $\frac{FP}{TP + FP}$

\textbf{AUROC}: TPR (y) vs. FPR (x)

\textbf{F1-Score}: $\frac{2TP}{2TP+FP+FN}=\frac{2}{1/Precision+1/Recall}$, $\text{Accuracy}: \frac{\text{TP + TN}}{\text{P + N}} = \frac{TP + TN}{TP + TN + FP + FN}$

Goal: large recall and small FPR.
